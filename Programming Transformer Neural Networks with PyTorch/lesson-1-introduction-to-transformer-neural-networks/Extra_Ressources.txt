PyTorch Embedding Layers(opens in a new tab) - Documentation on the nn.Embedding layer in PyTorch, explaining how to create and use embedding layers.
	- https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html
Creating Custom Embeddings(opens in a new tab) - A guide to creating custom word embeddings, with principles applicable across different frameworks, including PyTorch.
	- https://www.tensorflow.org/text/guide/word_embeddings?hl=fr
Transformers: Attention Is All You Need(opens in a new tab) - The original research paper introducing the Transformer architecture, detailing the components and innovations of the model.
	- https://arxiv.org/abs/1706.03762
The Transformer Model and Masked Language Modeling - Documentation on GPT-2 and its use of masked language modeling to ensure valid training processes.
	https://huggingface.co/docs/transformers/model_doc/gpt2
PyTorch Dropout Documentation(opens in a new tab) - Official documentation on the torch.nn.Dropout layer in PyTorch, explaining its usage and parameters.
	https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html
The Original Dropout Paper - "Dropout: A Simple Way to Prevent Neural Networks from Overfitting" by Srivastava et al., which introduced the dropout technique.
	https://jmlr.org/papers/v15/srivastava14a.html
PyTorch DataLoader Documentation - Official documentation on DataLoader, which is used for loading data in batches during training.
	https://pytorch.org/docs/stable/data.html
Optimizers in PyTorch - Information on different optimization algorithms provided by PyTorch, including their uses and parameters.
	https://pytorch.org/docs/stable/optim.html
PyTorch Documentation - Comprehensive guide and reference for PyTorch, covering modules, functions, and classes.
	https://pytorch.org/docs/stable/index.html
AdamW Optimizer in PyTorch - Information about the AdamW optimizer, which helps in weight decay and improving training stability.
	https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html