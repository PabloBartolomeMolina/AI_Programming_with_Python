{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ulgnkbbvEt6u"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All good!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "cuda_is_available = torch.cuda.is_available()\n",
    "\n",
    "if cuda_is_available:\n",
    "  print(\"All good!\")\n",
    "else:\n",
    "  print(\"CUDA is NOT available!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "7R6RnqQu0-P9"
   },
   "outputs": [],
   "source": [
    "# You can use this prompt or try something else!\n",
    "prompt = \"During the latest presentation OpenAI\"\n",
    "# A good model for this exercise, but feel free to use another model: https://huggingface.co/models?pipeline_tag=text-generation&sort=downloads\n",
    "model = \"openai-community/gpt2-large\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "hkVKzDegAItu"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Step 1 - Set Up the Text Generation Pipeline\n",
    "\n",
    "# Import \"pipeline\" function\n",
    "from transformers import pipeline\n",
    "\n",
    "# Create a pipeline for text generation, selected model, and \"device=0\" (to use CUDA)\n",
    "text_generator = pipeline(\"text-generation\", model=model, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "_xUAq3XiAN1z"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text:\n",
      "During the latest presentation OpenAI, a startup founded by a group of Stanford researchers, unveiled an algorithm called Neural Networks for Visual Recognition, or MNREV, which is built on a combination of three AI techniques: convolutional neural networks (CNNs), recurrent neural networks (RNNs), and perceptron-based architectures.\n",
      "\n",
      "CNNs is a network structure with many layers, and is an approach that has grown up recently in the field of image processing.\n",
      "\n",
      "It's\n"
     ]
    }
   ],
   "source": [
    "# Step 2 - Generate text with the default settings\n",
    "\n",
    "# Generate text with the selected prompt\n",
    "generated_texts = text_generator(prompt, max_length=100, num_return_sequences=1)\n",
    "\n",
    "print(f\"Generated text:\\n{generated_texts[0]['generated_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "rGcDDPcz1Ln5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "Parameters:\n",
      "-----------------------------------\n",
      "do_sample=False\n",
      "-----------------------------------\n",
      "Generation:\n",
      "-----------------------------------\n",
      "During the latest presentation OpenAI's CEO, John Robb, said that the company is working on a \"biggest AI project ever\" and that it is \"going to be a big deal.\"\n",
      "\n",
      "Robb also said that the company is working on a \"biggest AI project ever\" and that it is \"going to be a big deal.\"\n",
      "\n",
      "\"We're going to be a big deal,\" he said. \"We're going to be the biggest AI project ever.\"\n",
      "\n",
      "\n",
      "-----------------------------------\n",
      "\n",
      "\n",
      "\n",
      "-----------------------------------\n",
      "Parameters:\n",
      "-----------------------------------\n",
      "do_sample=True\n",
      "-----------------------------------\n",
      "Generation:\n",
      "-----------------------------------\n",
      "During the latest presentation OpenAI's Kevin Kelly introduced the latest version of the game, FTL: Faster Then Light. He demonstrated a \"speedrun\" on a 32-player server, in which he was able to complete each stage with only 3 minutes, 15 seconds of added time, a slight deviation from his actual time.\n",
      "\n",
      "According to Kelly, in the game AI is about to reach a level that they've had difficulties with before. At this level there will be a major bottleneck on\n",
      "-----------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 3 - Experiment with Different Parameters\n",
    "\n",
    "# Now try different parameters\n",
    "\n",
    "# Try text generation with \"do_sample\" parameter equal to `True` or `False`\n",
    "for do_sample in [\n",
    "    False, # Greedy Search\n",
    "    True   # Multinomial sampling\n",
    "  ]:\n",
    "  generated_texts = text_generator(prompt, max_length=100, num_return_sequences=1, do_sample=do_sample, num_beams=1)\n",
    "\n",
    "  print(\"-----------------------------------\")\n",
    "  print(\"Parameters:\")\n",
    "  print(\"-----------------------------------\")\n",
    "  print(f\"do_sample={do_sample}\")\n",
    "  print(\"-----------------------------------\")\n",
    "  print(\"Generation:\")\n",
    "  print(\"-----------------------------------\")\n",
    "  print(generated_texts[0]['generated_text'])\n",
    "  print(\"-----------------------------------\")\n",
    "  print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "uo3CC3yk4QmC"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "Parameters:\n",
      "-----------------------------------\n",
      "num_beams=1\n",
      "-----------------------------------\n",
      "Generation:\n",
      "-----------------------------------\n",
      "During the latest presentation OpenAI's CEO, John Robb, said that the company is working on a \"biggest AI project ever\" and that it is \"going to be a big deal.\"\n",
      "\n",
      "Robb also said that the company is working on a \"biggest AI project ever\" and that it is \"going to be a big deal.\"\n",
      "\n",
      "\"We're going to be a big deal,\" he said. \"We're going to be the biggest AI project ever.\"\n",
      "\n",
      "\n",
      "-----------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "Parameters:\n",
      "-----------------------------------\n",
      "num_beams=3\n",
      "-----------------------------------\n",
      "Generation:\n",
      "-----------------------------------\n",
      "During the latest presentation OpenAI's CEO and co-founder Demis Hassabis said, \"We're excited to announce that we've been working with the OpenAI team for the past few months on a new AI research project. We're excited to be working with the OpenAI team on a new AI research project. We're excited to be working with the OpenAI team on a new AI research project. We're excited to be working with the OpenAI team on a new AI research project.\n",
      "-----------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "Parameters:\n",
      "-----------------------------------\n",
      "num_beams=5\n",
      "-----------------------------------\n",
      "Generation:\n",
      "-----------------------------------\n",
      "During the latest presentation OpenAI's CEO and co-founder Demis Hassabis said:\n",
      "\n",
      "\"We've been working on this for a long time. We've been working on this for a long time. We've been working on this for a long time. We've been working on this for a long time. We've been working on this for a long time. We've been working on this for a long time. We've been working on this for a long time. We've\n",
      "-----------------------------------\n",
      "\n",
      "\n",
      "\n",
      "-----------------------------------\n",
      "Parameters:\n",
      "-----------------------------------\n",
      "num_beams=10\n",
      "-----------------------------------\n",
      "Generation:\n",
      "-----------------------------------\n",
      "During the latest presentation OpenAI CEO and co-founder Demis Hassabis said:\n",
      "\n",
      "\"We've been working on this for a long time. We've been working on this for a long time. We've been working on this for a long time. We've been working on this for a long time. We've been working on this for a long time. We've been working on this for a long time. We've been working on this for a long time. We've been\n",
      "-----------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Try text generation using \"Beam-search strategy\"\n",
    "for beams in [1, 3, 5, 10]:\n",
    "  generated_texts = text_generator(prompt, max_length=100, num_return_sequences=1, do_sample=False, num_beams=beams)\n",
    "\n",
    "  print(\"-----------------------------------\")\n",
    "  print(\"Parameters:\")\n",
    "  print(\"-----------------------------------\")\n",
    "  print(f\"num_beams={beams}\")\n",
    "  print(\"-----------------------------------\")\n",
    "  print(\"Generation:\")\n",
    "  print(\"-----------------------------------\")\n",
    "  print(generated_texts[0]['generated_text'])\n",
    "  print(\"-----------------------------------\")\n",
    "  print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "K96hVRPC6MUR"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "Parameters:\n",
      "-----------------------------------\n",
      "num_beams=1\n",
      "-----------------------------------\n",
      "Generation:\n",
      "-----------------------------------\n",
      "During the latest presentation OpenAI and its research partner DeepMind, founder and CEO Demis Hassabis said, \"The fact that we get to show our AI solutions at CES, and not just at that, and talk to them directly – it's really exciting. We're happy to be able to show people how we're able to take the world by storm.\"\n",
      "\n",
      "After the presentations at CES, the company will provide an AI conference at the Siggraph International Computer Science Conference in Las Vegas\n",
      "-----------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "Parameters:\n",
      "-----------------------------------\n",
      "num_beams=3\n",
      "-----------------------------------\n",
      "Generation:\n",
      "-----------------------------------\n",
      "During the latest presentation OpenAI's co-founder Demis Hassabis said that the company was \"very excited\" to be working with Google.\n",
      "\n",
      "Google has been working with OpenAI for a while now, and they've been using the company's deep learning technology to build a self-driving car.\n",
      "\n",
      "Hassabis said that Google was \"very excited\" to be working with OpenAI.\n",
      "\n",
      "\"We are very excited to be working with Google,\" he said.\n",
      "\n",
      "\n",
      "-----------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "Parameters:\n",
      "-----------------------------------\n",
      "num_beams=5\n",
      "-----------------------------------\n",
      "Generation:\n",
      "-----------------------------------\n",
      "During the latest presentation OpenAI CEO Demis Hassabis said, \"We're going to see a lot more of this kind of stuff in the future, and it's going to be really interesting to see how it all plays out.\"\n",
      "\n",
      "Hassabis added, \"There's a lot of things you can do with AI that you can't do with humans, and we're going to see a lot more of that in the future, and it's going to be really interesting to see how\n",
      "-----------------------------------\n",
      "\n",
      "\n",
      "\n",
      "-----------------------------------\n",
      "Parameters:\n",
      "-----------------------------------\n",
      "num_beams=10\n",
      "-----------------------------------\n",
      "Generation:\n",
      "-----------------------------------\n",
      "During the latest presentation OpenAI's director of research, Ilya Sutskever, said that his team had been working on the problem for more than a decade.\n",
      "\n",
      "\"We've been working on this problem for more than a decade,\" Sutskever said.\n",
      "\n",
      "\"We've been working on this problem for more than a decade,\" Ilya Sutskever said.\n",
      "\n",
      "\"We've been working on this problem for more than a decade,\" Ilya Suts\n",
      "-----------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Try text generation using \"Beam-search multinomial sampling\"\n",
    "for beams in [1, 3, 5, 10]:\n",
    "  generated_texts = text_generator(prompt, max_length=100, num_return_sequences=1, do_sample=True, num_beams=beams)\n",
    "\n",
    "  print(\"-----------------------------------\")\n",
    "  print(\"Parameters:\")\n",
    "  print(\"-----------------------------------\")\n",
    "  print(f\"num_beams={beams}\")\n",
    "  print(\"-----------------------------------\")\n",
    "  print(\"Generation:\")\n",
    "  print(\"-----------------------------------\")\n",
    "  print(generated_texts[0]['generated_text'])\n",
    "  print(\"-----------------------------------\")\n",
    "  print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "f5R7GeD3AUgp"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "Parameters:\n",
      "-----------------------------------\n",
      "top_k=1\n",
      "-----------------------------------\n",
      "Generation:\n",
      "-----------------------------------\n",
      "During the latest presentation OpenAI's CEO, John Robb, said that the company is working on a \"biggest AI project ever\" and that it is \"going to be a big deal.\"\n",
      "\n",
      "Robb also said that the company is working on a \"biggest AI project ever\" and that it is \"going to be a big deal.\"\n",
      "\n",
      "\"We're going to be a big deal,\" he said. \"We're going to be the biggest AI project ever.\"\n",
      "\n",
      "\n",
      "-----------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "Parameters:\n",
      "-----------------------------------\n",
      "top_k=5\n",
      "-----------------------------------\n",
      "Generation:\n",
      "-----------------------------------\n",
      "During the latest presentation OpenAI's CEO John Robb said,\n",
      "\n",
      "We're really proud of the work that we've been doing in this field, and we're looking forward to the day that we're able to make this a reality.\n",
      "\n",
      "Robb is the cofounder of OpenAI, the company behind the Deep Learning project. The team is working on a project called \"Reinforcement Learning for Games,\" which is designed to improve AI games by giving it the ability to learn from its\n",
      "-----------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "Parameters:\n",
      "-----------------------------------\n",
      "top_k=10\n",
      "-----------------------------------\n",
      "Generation:\n",
      "-----------------------------------\n",
      "During the latest presentation OpenAI has been working with the University of Toronto in Toronto, and it's been working with other universities around the world, including Google. In the past few months, the team has been collaborating on a series of experiments in which they have trained a neural net to play a variety of board games, including Go. These tests show that it can learn how to play Go, and then to play the other board games as well.\n",
      "\n",
      "This new game, called \"Go for\n",
      "-----------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "Parameters:\n",
      "-----------------------------------\n",
      "top_k=50\n",
      "-----------------------------------\n",
      "Generation:\n",
      "-----------------------------------\n",
      "During the latest presentation OpenAI's CEO and lead engineer, Andrew Ng, pointed out another use case for the research: The team's goal is to create a universal deep learning framework that could run on large commercial systems. In this case, it's a platform that would allow researchers to apply their algorithms from machine learning to any problem they desire.\n",
      "\n",
      "\"If you have a robot with a human as an engineer, and you want to drive and see if you can do things that look like the\n",
      "-----------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "Parameters:\n",
      "-----------------------------------\n",
      "top_k=100\n",
      "-----------------------------------\n",
      "Generation:\n",
      "-----------------------------------\n",
      "During the latest presentation OpenAI has been giving from NYC, I got in touch with their CEO Peter Norvig and asked him a couple of questions about OpenAI. Peter has an interesting background, as far as I know being one of the founding members of Stanford University's AI lab, and in May 2015 he resigned as CEO (although this is a moot point, as he moved to a more prominent role in the company).\n",
      "\n",
      "Peter is currently heavily involved with OpenAI as they conduct research\n",
      "-----------------------------------\n",
      "\n",
      "\n",
      "\n",
      "-----------------------------------\n",
      "Parameters:\n",
      "-----------------------------------\n",
      "top_k=500\n",
      "-----------------------------------\n",
      "Generation:\n",
      "-----------------------------------\n",
      "During the latest presentation OpenAI.ai's director of communications Anthony Levandowski said that their virtual agent will be \"a neural network\" that could be implemented with so-called reinforcement learning.\n",
      "\n",
      "The company described an exoskeleton called The REM.Y, an exoskeleton that levitates to the ground using a lightweight, remote-controlled movement rather than stiff straps. The REM.Y even has a \"smart\" driver that automatically unzips and zips around to accommodate its wearer\n",
      "-----------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Try text generation with different \"top_k\" values. E.g. from 1 to 500\n",
    "for k in [1, 5, 10, 50, 100, 500]:\n",
    "  generated_texts = text_generator(prompt, max_length=100, num_return_sequences=1, top_k=k)\n",
    "\n",
    "  print(\"-----------------------------------\")\n",
    "  print(\"Parameters:\")\n",
    "  print(\"-----------------------------------\")\n",
    "  print(f\"top_k={k}\")\n",
    "  print(\"-----------------------------------\")\n",
    "  print(\"Generation:\")\n",
    "  print(\"-----------------------------------\")\n",
    "  print(generated_texts[0]['generated_text'])\n",
    "  print(\"-----------------------------------\")\n",
    "  print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "yXOuaxe0RJwf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "Parameters:\n",
      "-----------------------------------\n",
      "temperature=0.1\n",
      "-----------------------------------\n",
      "Generation:\n",
      "-----------------------------------\n",
      "During the latest presentation OpenAI's CEO, John Robb, said that the company is \"very excited\" about the potential of the technology.\n",
      "\n",
      "\"We're very excited about the potential of deep learning,\" he said. \"We're very excited about the potential of deep learning. We're very excited about the potential of deep learning. We're very excited about the potential of deep learning. We're very excited about the potential of deep learning. We're very excited about the potential of deep learning\n",
      "-----------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "Parameters:\n",
      "-----------------------------------\n",
      "temperature=0.5\n",
      "-----------------------------------\n",
      "Generation:\n",
      "-----------------------------------\n",
      "During the latest presentation OpenAI's Deep Learning Research Group is presenting at the NIPS conference in Barcelona, Spain.\n",
      "\n",
      "The group's first project was to create a neural network that can learn to recognize faces. The group used a mixture of deep learning and convolutional neural networks to achieve this.\n",
      "\n",
      "The team used a deep learning model to train the model, which was trained on images of human faces. The model learned to recognize faces based on the images of the people it was training\n",
      "-----------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "Parameters:\n",
      "-----------------------------------\n",
      "temperature=1.0\n",
      "-----------------------------------\n",
      "Generation:\n",
      "-----------------------------------\n",
      "During the latest presentation OpenAI has done on its machine learning machine, the crowd at its offices at Google, where much of the machine learning work is done, gasped when Robert Hanson, a senior member of the artificial intelligence team, demonstrated using deep brain analysis to decode an encrypted message from a Chinese phone conversation.\n",
      "\n",
      "\"It was literally a 'oh' moment,\" says Hanson, speaking by phone from California. \"You could barely see his face. He looked absolutely shocked and confused.\"\n",
      "\n",
      "\n",
      "-----------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "Parameters:\n",
      "-----------------------------------\n",
      "temperature=1.5\n",
      "-----------------------------------\n",
      "Generation:\n",
      "-----------------------------------\n",
      "During the latest presentation OpenAI researchers will demonstrate their capabilities to create autonomous vehicles in more realistic scenarios, ranging from a driving simulation in Hollywood movie to the very unlikely scenario of someone sitting in a car parked without steering wheel and pedals. This is an example of OpenAI's collaborative research, as these projects have had very beneficial results as each partner group can come out with better and more exciting results during the period provided.\n",
      "\n",
      "Read our news summary at: www.ontruman.com/news\n",
      "-----------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "Parameters:\n",
      "-----------------------------------\n",
      "temperature=2.0\n",
      "-----------------------------------\n",
      "Generation:\n",
      "-----------------------------------\n",
      "During the latest presentation OpenAI co-founder and Facebook professor Mike Hanson was asking, \"Why is he smiling?\" We immediately understood why — for his group has used deep AI simulations for quite a while that allow more realistic expectations.\" We're still refining them internally.\" On the final topic though, our conversation on an upcoming research venture the venture capitalist Joe Laney asked us why and what their plans for a post-disclosure policy involve in his recent tweet; \"We would prefer they did not announce\n",
      "-----------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "Parameters:\n",
      "-----------------------------------\n",
      "temperature=2.5\n",
      "-----------------------------------\n",
      "Generation:\n",
      "-----------------------------------\n",
      "During the latest presentation OpenAI researcher Brian Hoffman mentioned:\n",
      "'I can use this software you put out or build for myself if there come any real-live cases, maybe one or two.'\n",
      "\n",
      " it was the second day the AI expert said in May.\n",
      "Another notable developer in 2017 was Robert Morris. On 27th October the Stanford robotics grad told CNN 'My hope here here really from AI's evolution, especially since 2010 when DeepMind had the vision, deep vision of this kind is now\n",
      "-----------------------------------\n",
      "\n",
      "\n",
      "\n",
      "-----------------------------------\n",
      "Parameters:\n",
      "-----------------------------------\n",
      "temperature=3.0\n",
      "-----------------------------------\n",
      "Generation:\n",
      "-----------------------------------\n",
      "During the latest presentation OpenAI released yesterday during which AI experts said the game we're stuck in currently could very well have gone up in volume. AI scientists can help design better online communities. Companies cannot. \"Facebook could be the place,\" CEO Mark Pincis joked, that everyone should go out—unless someone decides to start another one.\n",
      "-----------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Try text generation with different \"temperature\" values. E.g. from 0.1 to 3.0\n",
    "for temp in [0.1, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0]:\n",
    "  generated_texts = text_generator(prompt, max_length=100, num_return_sequences=1, temperature=temp)\n",
    "\n",
    "  print(\"-----------------------------------\")\n",
    "  print(\"Parameters:\")\n",
    "  print(\"-----------------------------------\")\n",
    "  print(f\"temperature={temp}\")\n",
    "  print(\"-----------------------------------\")\n",
    "  print(\"Generation:\")\n",
    "  print(\"-----------------------------------\")\n",
    "  print(generated_texts[0]['generated_text'])\n",
    "  print(\"-----------------------------------\")\n",
    "  print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UUiu5ZdT9ArW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
